{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Dream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Deep Dream, or *Inceptionism*, was introduced by Google in [this](https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) blogpost. Deep Dream is an algorithm that optimizes an input image so that it maximizes its activations in certain layer(s) of a pretrained network. By this optimization process, different patterns, objects or shapes appear in the image based on what the neurons of the network have previously learned. Here is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figs/skyarrow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this exercise we will implement the algorithm in Keras and test it on some example images to see its effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.layers import Input\n",
    "from dream import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will use the same image for the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "\n",
    "img_dir = '../images/dream/sky1024px.jpg'\n",
    "I = imread(img_dir)\n",
    "plt.imshow(I)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here are the settings we will use, including the layers of the network we want to \"dream\" and the weights for each loss term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "settings = {'features': {'block5_conv1': 0.05,\n",
    "                         'block5_conv2': 0.1},\n",
    "            'continuity': 0.1,\n",
    "            'dream_l2': 0.02}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We load the pretrained network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "width, height = load_img(img_dir).size\n",
    "img_height = 600\n",
    "img_width = int(width * img_height / height)\n",
    "\n",
    "img_size = (img_height, img_width, 3)\n",
    "dream_in = Input(batch_shape=(1,) + img_size)\n",
    "model = vgg16.VGG16(input_tensor=dream_in,weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Deep Dream is a gradient ascent process that tries to maximize the L2 norm of activations of certain layer(s) of the network. Let's define the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dictionary with all layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# define the loss\n",
    "loss = K.variable(0.)\n",
    "\n",
    "for layer_name in settings['features']:\n",
    "    \n",
    "    assert layer_name in layer_dict.keys(), 'Layer ' + layer_name + ' not found in model.'\n",
    "    coeff = settings['features'][layer_name]\n",
    "    x = layer_dict[layer_name].output\n",
    "    shape = layer_dict[layer_name].output_shape\n",
    "    \n",
    "    # Maximize L2 norm of activations: loss is -activations\n",
    "    # we avoid border artifacts by only involving non-border pixels in the loss\n",
    "    loss -= coeff * K.sum(K.square(x[:, 2: shape[1] - 2, 2: shape[2] - 2, :])) / np.prod(shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Some additional loss terms are added to make the image look nicer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# add continuity loss (gives image local coherence, can result in an artful blur)\n",
    "loss += settings['continuity'] * continuity_loss(dream_in,img_height, img_width) / np.prod(img_size)\n",
    "# add image L2 norm to loss (prevents pixels from taking very high values, makes image darker)\n",
    "loss += settings['dream_l2'] * K.sum(K.square(dream_in)) / np.prod(img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We define the function that will compute the gradients ```grads``` of the image in ```dream_in``` based on the ```loss``` we just defined. This function is the one that will be used iteratively to update the image based on the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compute the gradients of the dream wrt the loss\n",
    "grads = K.gradients(loss, dream_in)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([dream_in], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's run it. We will run 5 iterations, in which we will forward the image, compute the gradients based on the loss and apply the gradients to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator(img_size,f_outputs)\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the loss\n",
    "\n",
    "ims = []\n",
    "iterations = 10\n",
    "\n",
    "x = preprocess_image(img_dir,img_height, img_width)\n",
    "\n",
    "for i in range(iterations):\n",
    "    # run L-BFGS for 7 steps\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=7)\n",
    "    print(i,'Current loss value:', min_val)\n",
    "    # decode the dream and save it\n",
    "    x = x.reshape(img_size)\n",
    "    img = deprocess_image(np.copy(x),img_height, img_width)\n",
    "    ims.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can display the image for the last 5 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, len(ims[:5]),figsize=(20,20))\n",
    "\n",
    "for i,im in enumerate(ims[:5]):\n",
    "    axarr[i].imshow(im)\n",
    "    axarr[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And let's display the final image with higher resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20)) \n",
    "plt.imshow(ims[-1])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Through this iterative process, we see that some shapes, patterns and even object-like blobs have emerged in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise:** You can now try the algorithm with different images from the ```images``` folder. You can also experiment with different layers in the network, different combinations and different weights. What happens when you choose early layers in the network? And when you use later ones? Are the shapes different?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
